{"cells":[{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"D989134F7553489EA949D98667A04809","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"# 深度学习与艺术 - 神经风格迁移\n\n欢迎来到本周的作业2。在本次作业中，你将学习神经风格迁移。该算法由Gatys等人在2015年创建(https://arxiv.org/abs/1508.06576)。\n\n**在此作业中，你将：**\n- 实现神经风格迁移算法\n- 使用算法生成新颖的艺术图像\n\n目前你研究的大多数算法都会优化损失函数以获得一组参数值。而在神经样式转换中，你将学习优化损失函数以获得像素值！"},{"metadata":{"id":"0B37156BEAE84418B5BFC1B2F148B7D5","slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"/home/kesci/input/deeplearning122839\n","name":"stdout"}],"source":"cd /home/kesci/input/deeplearning122839","execution_count":2},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"23C700FFBFC64DE0AD332836EBFB082F","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"import os\nimport sys\nimport scipy.io\nimport scipy.misc\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\nfrom nst_utils import *\nimport numpy as np\nimport tensorflow as tf\n\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"4B4C3B0EBF71415D8B489B46E6C38EE5","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 1 问题陈述\n\n神经风格迁移（NST）是深度学习中最有趣的技术之一。如下所示，它将“内容”图像（Content）和“风格”图像（Style）合并在一起，以创建“生成”图像（Generated）。生成的图像G将图像C的“内容”与图像S的“风格”组合在一起。\n\n在此示例中，你将巴黎卢浮宫博物馆的图像（内容图像C）与印象派运动的领导者克劳德·莫奈的作品（风格图像S）混合在一起以生成新的图像。\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yvp2wi04.png?imageView2/0/w/960/h/960)\n\n让我们看看如何做到这一点。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"99A0FD1FC45343EA88CAA52F57D2649D","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 2 迁移学习\n\n神经风格迁移（NST）使用以前训练过的卷积网络，并以此为基础。将之前经过不同任务训练的网络应用于新任务的想法叫做迁移学习。\n\n遵循原始的[NST论文](https://arxiv.org/abs/1508.06576)，我们将使用VGG网络。具体来说，我们将使用VGG-19，这是VGG网络的19层版本。该模型已经在非常大的ImageNet数据库上进行了训练，因此已经学会了识别各种低层特征和高层特征。\n\n运行以下代码以从VGG模型加载参数。这可能需要几秒钟。"},{"cell_type":"code","execution_count":4,"metadata":{"slideshow":{"slide_type":"slide"},"id":"403FBF2B0F2D4B3B935039EDF091ECF5","collapsed":false,"scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n{'input': <tf.Variable 'Variable:0' shape=(1, 300, 400, 3) dtype=float32_ref>, 'conv1_1': <tf.Tensor 'Relu:0' shape=(1, 300, 400, 64) dtype=float32>, 'conv1_2': <tf.Tensor 'Relu_1:0' shape=(1, 300, 400, 64) dtype=float32>, 'avgpool1': <tf.Tensor 'AvgPool:0' shape=(1, 150, 200, 64) dtype=float32>, 'conv2_1': <tf.Tensor 'Relu_2:0' shape=(1, 150, 200, 128) dtype=float32>, 'conv2_2': <tf.Tensor 'Relu_3:0' shape=(1, 150, 200, 128) dtype=float32>, 'avgpool2': <tf.Tensor 'AvgPool_1:0' shape=(1, 75, 100, 128) dtype=float32>, 'conv3_1': <tf.Tensor 'Relu_4:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv3_2': <tf.Tensor 'Relu_5:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv3_3': <tf.Tensor 'Relu_6:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv3_4': <tf.Tensor 'Relu_7:0' shape=(1, 75, 100, 256) dtype=float32>, 'avgpool3': <tf.Tensor 'AvgPool_2:0' shape=(1, 38, 50, 256) dtype=float32>, 'conv4_1': <tf.Tensor 'Relu_8:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv4_2': <tf.Tensor 'Relu_9:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv4_3': <tf.Tensor 'Relu_10:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv4_4': <tf.Tensor 'Relu_11:0' shape=(1, 38, 50, 512) dtype=float32>, 'avgpool4': <tf.Tensor 'AvgPool_3:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_1': <tf.Tensor 'Relu_12:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_2': <tf.Tensor 'Relu_13:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_3': <tf.Tensor 'Relu_14:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_4': <tf.Tensor 'Relu_15:0' shape=(1, 19, 25, 512) dtype=float32>, 'avgpool5': <tf.Tensor 'AvgPool_4:0' shape=(1, 10, 13, 512) dtype=float32>}\n","name":"stdout"}],"source":"model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\nprint(model)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"DB5C6F47E4994BE3935505FD48AEA47F","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"该模型存储在python字典中，其中每个变量名称都是键，而对应的值是包含该变量值的张量。要通过此网络测试图像，只需要将图像提供给模型。在TensorFlow中，你可以使用 [tf.assign](https://www.tensorflow.org/api_docs/python/tf/assign)函数执行此操作。特别地，你将使用如下的assign函数：\n```python\nmodel[\"input\"].assign(image)\n```\n这会将图像分配为模型的输入。此后，如果要访问特定层的激活函数，例如当网络在此图像上运行时说`4_2` 层，则可以在正确的张量`conv4_2`上运行TensorFlow会话，如下所示：\n```python\nsess.run(model[\"conv4_2\"])\n```"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"9546E4622FAA48B78708BE4FE0E1B96B","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"## 3 神经风格迁移\n\n我们将分三步构建NST算法：\n\n- 建立内容损失函数 $J_{content}(C,G)$；\n- 建立风格损失函数$J_{style}(S,G)$；\n- 放在一起得出$J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$。\n\n### 3.1 计算内容损失\n\n在我们的运行示例中，内容图像C是巴黎卢浮宫博物馆的图片。运行下面的代码以查看卢浮宫的图片。"},{"cell_type":"code","execution_count":5,"metadata":{"scrolled":true,"slideshow":{"slide_type":"slide"},"id":"2126399757AA4590AE12C0E26192CAF8","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f0fb8097d68>"},"transient":{},"execution_count":5},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/2126399757AA4590AE12C0E26192CAF8/q1yw7tl1nn.png\">"},"transient":{}}],"source":"content_image = scipy.misc.imread(\"images/louvre.jpg\")\nimshow(content_image)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"2540F6A8AC5C47CEBABB463391AF8399","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"内容图像（C）显示了卢浮宫博物馆的金字塔，周围是古老的巴黎建筑，在晴朗的天空下只有几层云。\n\n**3.1.1 如何确保生成的图像G与图像C的内容匹配？**\n\n正如我们在课程中所讲述的，ConvNet的底层倾向于检测诸如边缘和简单纹理之类的低层特征，而深层则倾向于检测诸如纹理之类的更复杂的高层特征。\n\n我们希望生成的图像G具有与输入图像C相似的内容。假设你已选择某些层的激活来表示图像的内容。在实践中，如果在网络中间选择一个层，既不会太浅也不会太深，你将获得视觉上令人满意的结果。（完成本练习后，请随时返回并尝试使用不同的图层，以查看结果变化。）\n\n因此，假设你选择了一个特定的隐藏层使用。现在，将图像C设置为预训练的VGG网络的输入，并进行正向传播。假设$a^{(C)}$是你选择的层中的隐藏层激活。（在课程中，我们将其写为$a^{[l](C)}$，但在这里我们将删除上标$[l]$以简化表示手法。）这将是张量$n_H \\times n_W \\times n_C$。对图像G重复此过程：将G设置为输入，然后进行正向传播。令\n$$\na^{(G)}\n$$\n为相应的隐藏层激活。我们将内容损失函数定义为：\n\n$$\nJ_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2\\tag{1}\n$$\n\n在这里，$n_H, n_W$和$n_C$是你选择的隐藏层的高度，宽度和通道数，并以损失的归一化术语显示。请注意$a^{(C)}$和$a^{(G)}$是与隐藏层的激活对应的。为了计算损失$J_{content}(C,G)$，将这些3D体积展开为2D矩阵更方便，如下所示。（从技术上讲，此展开步骤不需要计算$J_{content}$，但是对于之后需要进行类似操作以计算样式$J_{style}$常数的情况来说，这将是一个很好的实践。）\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yvr1qi8g.png?imageView2/0/w/960/h/960)\n\n**练习**：使用TensorFlow计算“内容损失”。\n\n**说明**：实现此函数包含3个步骤：\n1. 从a_G检索尺寸：\n    - 要从张量X检索尺寸，请使用： `X.get_shape().as_list()`\n1. 如上图所示展开a_C和a_G\n    - 如果遇到问题，请查看 [Hint1](https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/transpose) 和 [Hint2](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/reshape)。\n1. 计算内容损失：\n    - 如果遇到问题，请查看 [Hint3](https://www.tensorflow.org/api_docs/python/tf/reduce_sum), [Hint4](https://www.tensorflow.org/api_docs/python/tf/square) 和 [Hint5](https://www.tensorflow.org/api_docs/python/tf/subtract)。\n"},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"1E9D8D73A5E444E98A14BA7C2D060031","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: compute_content_cost\n\ndef compute_content_cost(a_C, a_G):\n    \"\"\"\n    Computes the content cost\n    \n    Arguments:\n    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n    \n    Returns: \n    J_content -- scalar that you compute using equation 1 above.\n    \"\"\"\n    \n    ### START CODE HERE ###\n    # Retrieve dimensions from a_G (≈1 line)\n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n\n    # Reshape a_C and a_G (≈2 lines)\n    a_C_unrolled = tf.reshape(a_C,shape=(n_H* n_W,n_C))\n    a_G_unrolled = tf.reshape(a_G,shape=(n_H* n_W,n_C))\n\n    # compute the cost with tensorflow (≈1 line)\n    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled,a_G_unrolled)))/(4*n_H*n_W*n_C)\n    ### END CODE HERE ###\n    \n    return J_content"},{"cell_type":"code","execution_count":7,"metadata":{"slideshow":{"slide_type":"slide"},"id":"6E7CD61F8DA5469786585C675964603D","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"J_content = 6.7655935\n","name":"stdout"}],"source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    tf.set_random_seed(1)\n    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    J_content = compute_content_cost(a_C, a_G)\n    print(\"J_content = \" + str(J_content.eval()))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"9EEA9685EC50430A8ED63FBCB020C2BB","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nJ_content = 6.7655935"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C045E6E3DEA546A584F17322E40F49CD","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"\n**你应该记住**：\n- 内容损失需要对神经网络进行隐藏层激活，并计算$a^{(C)}$ 和 $a^{(G)}$之间的差异。\n- 当我们在最小化内容损失时，这将有助于确保$G$具有与$C$类似的内容。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"A97CDC72AD7B4C2E9862B3CC2B7BD528","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"### 3.2 计算风格损失\n\n我们将使用以下样式图像作为示例运行："},{"cell_type":"code","execution_count":8,"metadata":{"slideshow":{"slide_type":"slide"},"id":"1E2284B8FDB345D7A1E4944A8FDBB2C3","collapsed":false,"scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f0f585e4780>"},"transient":{},"execution_count":8},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/1E2284B8FDB345D7A1E4944A8FDBB2C3/q1yw8587tx.png\">"},"transient":{}}],"source":"style_image = scipy.misc.imread(\"images/monet_800600.jpg\")\nimshow(style_image)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"4DFD7765BA4240EF86279A0247BC6952","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"这幅画以*[印象派](https://en.wikipedia.org/wiki/Impressionism)*的风格绘制。\n\n让我们看看如何定义“风格”常数函数$J_{style}(S,G)$。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"DDC02356E1F74D5290447F2C054A9185","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"#### 3.2.1 风格矩阵\n\n风格矩阵也称为“语法矩阵”。在线性代数中，向量$(v_{1},\\dots ,v_{n})$的集合的Gram矩阵G是点积的矩阵，其项是${\\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j})  }$。换句话说，$G_{ij}$ 比较$v_i$ 与$v_j$的相似度：如果它们非常相似，则它们会具有较大的点积，因此$G_{ij}$也会较大。\n\n请注意，此处使用的变量名称存在冲突。我们遵循文献中使用的通用术语，但是$G$用于表示风格矩阵（或Gram矩阵）也表示生成的图像。我们将从上下文中确保清楚$G$的指代。\n\n在NST中，可以通过将“展开的”滤波器矩阵与其转置相乘来计算风格矩阵：\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yvs4v5op.png?imageView2/0/w/960/h/960)\n\n结果是维度为$(n_C,n_C)$的矩阵，其中$n_C$是滤波器的数量。值$G_{ij}$衡量滤波器$i$的激活与滤波器$j$的激活的相似度。\n\n语法矩阵的一个重要部分是对角元素（例如$G_{ii}$）也可以衡量滤波器$i$的活跃程度。例如，假设滤波器$i$正在检测图像中的垂直纹理。然后$G_{ii}$衡量整个图像中垂直纹理的普遍程度：如果$G_{ii}$大，则意味着图像具有很多垂直纹理。\n\n通过捕获不同类型特征的普遍性($G_{ii}$)以及一起出现多少不同特征($G_{ii}$)，样式矩阵$G$可以衡量图像的样式。\n\n**练习**：\n使用TensorFlow实现一个计算矩阵A的语法矩阵的函数。公式为：A的语法矩阵为$G_A = AA^T$。如果遇到问题，请查看[Hint 1](https://www.tensorflow.org/api_docs/python/tf/matmul) 和 [Hint 2](https://www.tensorflow.org/api_docs/python/tf/transpose)。"},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"37D7216093E34D53BEA886464EF68A2B","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: gram_matrix\n\ndef gram_matrix(A):\n    \"\"\"\n    Argument:\n    A -- matrix of shape (n_C, n_H*n_W)\n    \n    Returns:\n    GA -- Gram matrix of A, of shape (n_C, n_C)\n    \"\"\"\n    \n    ### START CODE HERE ### (≈1 line)\n    GA = tf.matmul(A,tf.transpose(A))\n    ### END CODE HERE ###\n\n    \n    return GA"},{"cell_type":"code","execution_count":10,"metadata":{"slideshow":{"slide_type":"slide"},"id":"D18C840706B1482F907788ED70C0A6FA","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"GA = [[ 6.422305 -4.429122 -2.096682]\n [-4.429122 19.465837 19.563871]\n [-2.096682 19.563871 20.686462]]\n","name":"stdout"}],"source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    tf.set_random_seed(1)\n    A = tf.random_normal([3, 2*1], mean=1, stddev=4)\n    GA = gram_matrix(A)\n    \n    print(\"GA = \" + str(GA.eval()))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"14A07C47490B42C38DE68A6069BE22FD","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nGA = [[ 6.422305 -4.429122 -2.096682]\n [-4.429122 19.465837 19.563871]\n [-2.096682 19.563871 20.686462]]"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"58978965D5D645799C4EFEA742ECD867","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"#### 3.2.2 风格损失"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"8F2790391351438286F8292D4D32D608","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"生成风格矩阵（Gram矩阵）后，你的目标是使\"style\"图像S的Gram矩阵和生成的图像G的Gram矩阵之间的距离最小。现在，我们仅使用单个隐藏层$a^{[l]}$，该层的相应的风格损失定义为：\n\n$$\nJ_{style}^{[l]}(S,G) = \\frac{1}{4 \\times {n_C}^2 \\times (n_H \\times n_W)^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(G^{(S)}_{ij} - G^{(G)}_{ij})^2\\tag{2}\n$$\n\n其中$G^{(S)}$ 和 $G^{(G)}$分别是“风格”图像和“生成的”图像的语法矩阵，使用针对网络中特定的隐藏层的激活来计算。\n"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"DB23E03251404EECB0187704414B06EA","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**练习**：计算单层的风格损失。\n\n**说明**：实现此函数的步骤是：\n1. 从隐藏层激活a_G中检索尺寸：\n     - 要从张量X检索尺寸，请使用：`X.get_shape().as_list()`\n1. 如上图所示，将隐藏层激活a_S和a_G展开为2D矩阵。\n     - 你可能会发现[Hint1](https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/transpose)和[Hint2](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/reshape)有用。\n1. 计算图像S和G的风格矩阵。（使用以前编写的函数）\n1. 计算风格损失：\n     - 你可能会发现 [Hint3](https://www.tensorflow.org/api_docs/python/tf/reduce_sum), [Hint4](https://www.tensorflow.org/api_docs/python/tf/square) 和 [Hint5](https://www.tensorflow.org/api_docs/python/tf/subtract) 有用。"},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"7560725504144BC48D2D37A1316FC077","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: compute_layer_style_cost\n\ndef compute_layer_style_cost(a_S, a_G):\n    \"\"\"\n    Arguments:\n    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n    \n    Returns: \n    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n    \"\"\"\n    \n     ### START CODE HERE ###\n    # Retrieve dimensions from a_G (≈1 line)\n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n\n    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n    a_S = tf.reshape(a_S,shape=(n_H* n_W,n_C))\n    a_G = tf.reshape(a_G,shape=(n_H* n_W,n_C))\n\n    # Computing gram_matrices for both images S and G (≈2 lines)\n    GS = gram_matrix(tf.transpose(a_S))\n    GG = gram_matrix(tf.transpose(a_G))\n\n    # Computing the loss (≈1 line)\n    J_style_layer =tf.reduce_sum(tf.square(tf.subtract(GS,GG)))/(4*(n_C*n_C)*(n_W * n_H) * (n_W * n_H))\n\n    ### END CODE HERE ###\n    \n    return J_style_layer"},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"E2259172932C4A38801EC70D6752C3CC","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"J_style_layer = 9.190278\n","name":"stdout"}],"source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    tf.set_random_seed(1)\n    a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n    J_style_layer = compute_layer_style_cost(a_S, a_G)\n    \n    print(\"J_style_layer = \" + str(J_style_layer.eval()))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"FD65DB9DFBF846C2817FE1598E0C9ACF","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nJ_style_layer = 9.190278"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"827FACD1FD0A4D9A9F92C300DF709DD4","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"#### 3.2.3 风格权重\n\n到目前为止，你仅从一层捕获了风格特征。如果我们从几个不同的层次“合并”风格损失，我们将获得更好的结果。完成此练习后，请随时返回并尝试不同的权重，以查看它如何更改生成的图像$G$。但现在而言，这是一个合理的默认值："},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"919C6B2CDA8C42488D8E1EFEEB68EE50","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"STYLE_LAYERS = [\n    ('conv1_1', 0.2),\n    ('conv2_1', 0.2),\n    ('conv3_1', 0.2),\n    ('conv4_1', 0.2),\n    ('conv5_1', 0.2)]"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"3C4E13033277454A86DA6FA6BF9E5BB3","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"你可以如下组合不同层的风格损失：\n\n$$\nJ_{style}(S,G) = \\sum_{l} \\lambda^{[l]} J^{[l]}_{style}(S,G)\n$$\n\n$\\lambda^{[l]}$的值在`STYLE_LAYERS`中给出。\n"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"A162CFD26A5A4D23B206434C30689351","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"我们已经实现了compute_style_cost（...）函数。它只是简单地多次调用你的compute_layer_style_cost（...），并使用`STYLE_LAYERS`中的值对结果进行加权。请仔细阅读以确保你了解它在做什么。\n\n\n```\n2.从STYLE_LAYERS循环（layer_name，coeff）：\n         a. 选择当前层的输出张量 例如，要从层\"conv1_1\"中调用张量，你可以这样做：out = model[\"conv1_1\"]\n         b. 通过在张量\"out\"上运行会话，从当前层获取style图像的风格\n         C. 获取一个表示当前层生成的图像风格的张量。 这只是\"out\"。\n         d. 现在，你拥有两种风格。使用上面实现的函数计算当前层的style_cost\n         e. 将当前层的（style_cost x coeff）添加到整体风格损失（J_style）中\n3.返回J_style，它现在应该是每层的（style_cost x coeff）之和。\n```\n"},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"2786DE76057646939F3F2A3DFE0F2EB3","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"def compute_style_cost(model, STYLE_LAYERS):\n    \"\"\"\n    Computes the overall style cost from several chosen layers\n    \n    Arguments:\n    model -- our tensorflow model\n    STYLE_LAYERS -- A python list containing:\n                        - the names of the layers we would like to extract style from\n                        - a coefficient for each of them\n    \n    Returns: \n    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n    \"\"\"\n    \n    # initialize the overall style cost\n    J_style = 0\n\n    for layer_name, coeff in STYLE_LAYERS:\n\n        # Select the output tensor of the currently selected layer\n        out = model[layer_name]\n\n        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n        a_S = sess.run(out)\n\n        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n        a_G = out\n        \n        # Compute style_cost for the current layer\n        J_style_layer = compute_layer_style_cost(a_S, a_G)\n\n        # Add coeff * J_style_layer of this layer to overall style cost\n        J_style += coeff * J_style_layer\n\n    return J_style"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"E3DB4F8C34DF439784084B5B6852FC57","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**注意**：在上述for循环的内部循环中，`a_G`是张量，尚未进行求值。当我们在下面的model_nn（）中运行TensorFlow计算图时，它将在每次迭代时进行评估和更新。\n\n<!-- \n你如何选择每一层的系数？较深的层捕获更复杂的特征，并且较深的层中的特征在图像中相对于彼此而言定位较少。因此，如果希望生成的图像柔和地跟随风格图像，请尝试为较深的层选择较大的权重，为第一层选择较小的权重。相反，如果希望生成的图像强烈遵循风格图像，请尝试为较低的层选择较小的权重，为第一层选择较大的权重\n!-->\n\n\n**你应该记住**：\n- 可以使用隐藏层激活的Gram矩阵表示图像的风格。但是，结合多个不同层的语法矩阵表示，我们可以获得更好的结果。这与内容表示法相反，后者通常仅使用一个隐藏层就足够了。\n- 最小化风格损失将导致图像$G$遵循图像$S$的风格。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"357D7BA18479464CA9B1C63CD4B33F5B","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"### 3.3 定义优化的总损失"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"B83119E1A2314E9AB488A52D560476A3","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"最后，让我们创建一个损失函数，以最小化风格和内容损失。公式为：\n\n$$\nJ(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)\n$$\n\n**练习**：实现总损失函数，其中包括内容损失和风格损失。"},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"54A3D0627DD641208DFB403325DBD9B7","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: total_cost\n\ndef total_cost(J_content, J_style, alpha = 10, beta = 40):\n    \"\"\"\n    Computes the total cost function\n    \n    Arguments:\n    J_content -- content cost coded above\n    J_style -- style cost coded above\n    alpha -- hyperparameter weighting the importance of the content cost\n    beta -- hyperparameter weighting the importance of the style cost\n    \n    Returns:\n    J -- total cost as defined by the formula above.\n    \"\"\"\n    \n    ### START CODE HERE ### (≈1 line)\n    J = alpha*J_content+beta*J_style\n    ### END CODE HERE ###\n\n    \n    return J"},{"cell_type":"code","execution_count":16,"metadata":{"slideshow":{"slide_type":"slide"},"id":"8CAC5BB6151242228FE53DD6AAAF5BD1","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"J = 35.34667875478276\n","name":"stdout"}],"source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    np.random.seed(3)\n    J_content = np.random.randn()    \n    J_style = np.random.randn()\n    J = total_cost(J_content, J_style)\n    print(\"J = \" + str(J))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"5A7E9A78D6F64B12B43BDA8B2895D85E","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nJ = 35.34667875478276"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C7714154B51C48EF8A1CD7248AFC1BC2","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"\n**你应该记住**：\n- 总损失是内容损失$J_{content}(C,G)$和风格损失$J_{style}(S,G)$的线性组合\n- $\\alpha$和$\\beta$是控制内容和风格之间相对权重的超参数"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"1B230800E51A4B2E82E64FC3C32F2A92","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 4 解决优化问题"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"3E3455EA003B4EEC873517D304867BF9","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"最后，让我们将所有内容组合在一起以实现神经风格迁移！\n\n\n该程序必须执行以下操作：\n\n1. 创建一个交互式会话\n1. 加载内容图像\n1. 加载风格图像\n1. 随机初始化要生成的图像\n1. 加载VGG16模型\n1. 构建TensorFlow计算图：\n\t*       通过VGG16模型运行内容图像并计算内容损失\n\t*       通过VGG16模型运行风格图像并计算风格损失\n\t*       计算总损失\n\t*       定义优化器和学习率\n1. 初始化TensorFlow图，并运行大量迭代，然后在每个步骤更新生成的图像。\n\n让我们详细介绍各个步骤。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"A96B952ADA1C4256A46DC69152BAD649","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"你之前已经实现了总损失 $J(G)$，我们现在将设置TensorFlow来针对$G$进行优化。 为此，你的程序必须重置计算图并使用\"[Interactive Session](https://www.tensorflow.org/api_docs/python/tf/InteractiveSession)\"。与常规会话不同，交互式会话将启动自身作为默认会话以构建计算图。这使你可以运行变量而无需经常引用会话对象，从而简化了代码。\n\n让我们开始交互式会话。"},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"FB925BEF9F764D0797FC9CBB750963C3","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# Reset the graph\ntf.reset_default_graph()\n\n# Start interactive session\nsess = tf.InteractiveSession()"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"2FA5B8CB512C41BA8FEF0504442B4BDB","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"让我们加载，重塑和标准化我们的“内容”图像（卢浮宫博物馆图片）："},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"0DD1740FD91A4B538C7097A95CC5271B","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}],"source":"content_image = scipy.misc.imread(\"images/louvre_small.jpg\")\ncontent_image = reshape_and_normalize_image(content_image)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C3FEEF63105B44C08061183AB8675D2A","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"加载，重塑和标准化我们的“风格”图像（克劳德·莫奈的画）："},{"cell_type":"code","execution_count":19,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"F51058020EAA48869EEE0662D4ED3C0E","scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}],"source":"style_image = scipy.misc.imread(\"images/monet.jpg\")\nstyle_image = reshape_and_normalize_image(style_image)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"68067C78269549E78E741B71DEC29974","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"现在，我们将“生成的”图像初始化作为从content_image创建的噪声图像。通过将生成图像的像素初始化为主要是噪声但仍与内容图像稍微相关的像素，这将有助于生成的图像的内容更快速地匹配“内容”图像的内容。（可以在`nst_utils.py`中查看`generate_noise_image（...）`的详细信息；为此，请在此Jupyter笔记本的左上角单击\"File-->Open...\"）"},{"cell_type":"code","execution_count":20,"metadata":{"slideshow":{"slide_type":"slide"},"id":"BA7CC2218A5844FC93D0533FC9DFF328","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","name":"stderr"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f0f58527f98>"},"transient":{},"execution_count":20},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/BA7CC2218A5844FC93D0533FC9DFF328/q1yw8tg9uj.png\">"},"transient":{}}],"source":"generated_image = generate_noise_image(content_image)\nimshow(generated_image[0])"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"004D3DED686B471F8DF6FAAEB5F2D4D6","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"接下来，如第（2）部分所述，让我们加载VGG16模型。"},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":false,"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"E3FE77E7492D4E8C9D61B2B0E39BAE03","jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"4353C501D3E94BA385960B6F7BC66059","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"为了获得计算内容损失的程序，我们现在将`a_C`和`a_G`分配为适当的隐藏层激活。我们将使用`conv4_2`层来计算内容损失。下面的代码执行以下操作：\n\n1.将内容图像分配为VGG模型的输入。\n2.将a_C设置为张量，为层\"conv4_2\"提供隐藏层激活。\n3.设置a_G为张量，为同一层提供隐藏层激活。\n4.使用a_C和a_G计算内容损失。"},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"7F7976A5FBF949E08F32C26E87AAF4D2","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# Assign the content image to be the input of the VGG model.  \nsess.run(model['input'].assign(content_image))\n\n# Select the output tensor of layer conv4_2\nout = model['conv4_2']\n\n# Set a_C to be the hidden layer activation from the layer we have selected\na_C = sess.run(out)\n\n# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\na_G = out\n\n# Compute the content cost\nJ_content = compute_content_cost(a_C, a_G)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"AA314AF99B98477DBD1805A3095BAE28","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**注意**：此时，a_G是张量，尚未验证。当我们在下面的model_nn（）中运行Tensorflow计算图时，它将在每次迭代时进行确认和更新。"},{"cell_type":"code","execution_count":23,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"BE96BD2F2C44406C8DF0D99C80D495F7","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# Assign the input of the model to be the \"style\" image \nsess.run(model['input'].assign(style_image))\n\n# Compute the style cost\nJ_style = compute_style_cost(model, STYLE_LAYERS)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"4CCB9DB9B8964AE5B83F493D362B6FBF","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**练习**：现在你有了J_content和J_style，通过调用`total_cost()`计算总损失J。 使用`alpha = 10` 和 `beta = 40`。"},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"CA4E23B807D040969E526ABE9A21D06F","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"### START CODE HERE ### (1 line)\nJ = total_cost(J_content, J_style, alpha = 10, beta = 40)\n### END CODE HERE ###"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"1E876FB106B146DB90435D71025398E4","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"你之前已经学习了如何在TensorFlow中设置Adam优化器。我们在这里使用2.0的学习率。 [See reference](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)"},{"cell_type":"code","execution_count":25,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"4E10BF5D83B940D58B5C5BE09F39B0D7","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# define optimizer (1 line)\noptimizer = tf.train.AdamOptimizer(2.0)\n\n# define train_step (1 line)\ntrain_step = optimizer.minimize(J)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"65865B911EB4417EB4FCC312E863029F","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**练习**：实现model_nn（）函数，该函数初始化tensorflow计算图的变量，将输入图像（初始生成的图像）作为VGG16模型的输入，并运行train_step进行训练步骤。"},{"cell_type":"code","execution_count":26,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"CAEB92231F0D4CE989EA7E225111A0AA","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"def model_nn(sess, input_image, num_iterations = 200):\n    \n    # Initialize global variables (you need to run the session on the initializer)\n    ### START CODE HERE ### (1 line)\n    sess.run(tf.global_variables_initializer())\n    ### END CODE HERE ###\n\n    # Run the noisy input image (initial generated image) through the model. Use assign().\n    ### START CODE HERE ### (1 line)\n    generated_image=sess.run(model['input'].assign(input_image))\n    ### END CODE HERE ###\n\n    for i in range(num_iterations):\n\n        # Run the session on the train_step to minimize the total cost\n        ### START CODE HERE ### (1 line)\n        sess.run(train_step)\n        ### END CODE HERE ###\n\n        # Compute the generated image by running the session on the current model['input']\n        ### START CODE HERE ### (1 line)\n        generated_image = sess.run(model['input'])\n        ### END CODE HERE ###\n\n        # Print every 20 iteration.\n        if i%20 == 0:\n            Jt, Jc, Js = sess.run([J, J_content, J_style])\n            print(\"Iteration \" + str(i) + \" :\")\n            print(\"total cost = \" + str(Jt))\n            print(\"content cost = \" + str(Jc))\n            print(\"style cost = \" + str(Js))\n            \n            # save current generated image in the \"/output\" directory\n            save_image(\"output/\" + str(i) + \".png\", generated_image)\n    \n    # save last generated image\n    save_image('output/generated_image.jpg', generated_image)\n    \n    return generated_image"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"D6E529CBD15A494EB4C719553E3F1A52","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"运行以下单元格以生成艺术图像。每运行20次迭代在CPU上大约需要3分钟，但是在大约140次迭代后你开始观察到好的结果。通常使用GPU训练神经风格迁移。"},{"cell_type":"code","execution_count":27,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"FE460BCCCAA547E6BB9BE778D6FE9962","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"Iteration 0 :\ntotal cost = 5050363000.0\ncontent cost = 7877.685\nstyle cost = 126257096.0\nIteration 20 :\ntotal cost = 943329150.0\ncontent cost = 15185.644\nstyle cost = 23579432.0\nIteration 40 :\ntotal cost = 484951500.0\ncontent cost = 16785.02\nstyle cost = 12119591.0\nIteration 60 :\ntotal cost = 312597280.0\ncontent cost = 17465.904\nstyle cost = 7810565.5\nIteration 80 :\ntotal cost = 228104380.0\ncontent cost = 17716.314\nstyle cost = 5698180.5\nIteration 100 :\ntotal cost = 180687200.0\ncontent cost = 17897.129\nstyle cost = 4512705.5\nIteration 120 :\ntotal cost = 150027140.0\ncontent cost = 18027.883\nstyle cost = 3746171.5\nIteration 140 :\ntotal cost = 127800170.0\ncontent cost = 18183.773\nstyle cost = 3190458.2\nIteration 160 :\ntotal cost = 110766376.0\ncontent cost = 18345.64\nstyle cost = 2764573.0\nIteration 180 :\ntotal cost = 97408580.0\ncontent cost = 18485.322\nstyle cost = 2430593.0\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([[[[-4.7703003e+01, -6.1550846e+01,  4.8832047e+01],\n         [-2.6217243e+01, -4.0605331e+01,  2.7117752e+01],\n         [-4.1859707e+01, -2.9068708e+01,  1.1424817e+01],\n         ...,\n         [-2.6815302e+01, -9.4887362e+00,  1.4312043e+01],\n         [-3.0232523e+01, -2.8368409e+00,  2.4125320e+01],\n         [-4.2427952e+01, -4.0595369e+00,  4.9285820e+01]],\n\n        [[-6.1166412e+01, -5.1801685e+01,  2.5211609e+01],\n         [-3.3077774e+01, -3.1084211e+01, -1.4618548e+00],\n         [-2.7152342e+01, -3.0673979e+01,  1.5284797e+01],\n         ...,\n         [-2.6783518e+01, -5.2329774e+00,  2.5989519e+01],\n         [-2.1495461e+01, -1.6955070e+01,  1.3927784e+01],\n         [-4.0914680e+01, -6.1364961e+00,  9.5178242e+00]],\n\n        [[-5.2238056e+01, -5.1577118e+01,  1.3660212e+01],\n         [-3.7201691e+01, -4.1442902e+01, -6.2615275e+00],\n         [-3.4184612e+01, -2.5266361e+01,  7.4517899e+00],\n         ...,\n         [-1.0611511e+01, -3.7342052e+01,  1.2602094e+01],\n         [-1.2320594e+01, -2.1005487e+01,  1.7151941e+01],\n         [-2.2562677e+01, -1.8515341e+01,  1.4285409e+01]],\n\n        ...,\n\n        [[-4.9188065e+01, -5.5147198e+01, -3.7267464e+01],\n         [-9.9028038e+01, -7.8261818e+01, -2.6933994e+02],\n         [-7.6436264e+01, -7.2988701e+01, -1.4288957e+02],\n         ...,\n         [-6.9915497e+01, -7.0040161e+01, -2.9220118e+01],\n         [-7.9575409e+01, -8.7896751e+01, -2.2540152e+01],\n         [ 1.4976151e+00, -3.9532539e+01,  2.4007713e+01]],\n\n        [[ 1.6301501e-01, -7.5239571e+01,  1.4685207e+01],\n         [-1.7506450e+02, -1.0348013e+02, -3.0651636e+01],\n         [ 6.6081967e+00, -7.1792625e+01, -1.9930256e+01],\n         ...,\n         [-9.5817398e+01, -8.4152191e+01, -4.7578541e+01],\n         [-1.0253343e+02, -1.0277041e+02, -5.9465641e+01],\n         [-6.5707291e+01, -9.5707497e+01,  1.8698233e+00]],\n\n        [[ 5.0412319e+01, -2.1662691e+01,  5.3101387e+01],\n         [ 3.1803602e+01, -8.5167076e+01,  2.6759926e+01],\n         [ 3.0552992e+01, -4.0452545e+01,  1.7949617e+01],\n         ...,\n         [-9.9841835e+01, -1.0824145e+02, -1.7334482e+01],\n         [-1.1805286e+02, -1.4513156e+02, -2.8111979e+01],\n         [-2.5438595e+01, -1.0570927e+02,  2.0523670e+01]]]],\n      dtype=float32)"},"transient":{},"execution_count":27}],"source":"model_nn(sess, generated_image)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"F7CBF39C4584468580D30C7D6BE801A2","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nIteration 0 :\ntotal cost = 5050363000.0\ncontent cost = 7877.685\nstyle cost = 126257096.0"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"67B3A51A44574E35A6E91D8D7C568355","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"你完成了！运行此命令后，在笔记本计算机的上方栏中单击\"File\"，然后单击\"Open\"。转到\"/output\"目录以查看所有已保存的图像。打开\"generated_image\"以查看生成的图像！\n\n你应该看到下面显示的图像：\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yytqqebj.png?imageView2/0/w/960/h/960)\n\n我们不想让你等待太久才能看到初始结果，因此已相应地设置了超参数。为了获得最佳效果，较长的优化算法（可能以较小的学习率）运行效果更好。完成并提交此作业后，我们建议你返回并使用此笔记本进行更多操作，看看是否可以生成外观更好的图像。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"42682654E1144D8C81CB565C8FA6CAD9","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"以下是一些其他示例：\n\n- 梵高（星空）风格的波斯波利斯（伊朗）古城的美丽废墟\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yyunym3o.png?imageView2/0/w/960/h/960)\n\n- 伊斯帕汗陶瓷风格的居鲁士大帝之墓\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yyvaovtp.png?imageView2/0/w/960/h/960)\n\n- 具有抽象蓝色液体绘画风格的湍流科学研究。\n\n![Image Name](https://cdn.kesci.com/upload/image/q1yyw2jl2k.png?imageView2/0/w/960/h/960)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"19F0600F496F4A328AC4D5C74A8543A8","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 5 使用你自己的图像进行测试（可选练习）"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"818C1C7D6A8B4B3A8A58CCE158FC841A","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"最后，你还可以在自己的图像上重新运行算法！\n\n为此，请回到第4部分，并使用你自己的图片更改内容图像和风格图像。以下是你应该执行的操作：\n\n1. 单击笔记本上部选项卡中的\"File -> Open\"\n1. 转到\"/images\"并上传图像(要求：(WIDTH = 300, HEIGHT = 225))，例如将其重命名为\"my_content.png\"和\"my_style.png\"\n1. 从以下位置更改部分（3.4）中的代码：\n```python\ncontent_image = scipy.misc.imread(\"images/louvre.jpg\")\nstyle_image = scipy.misc.imread(\"images/claude-monet.jpg\")\n```\n到:\n```python\ncontent_image = scipy.misc.imread(\"images/my_content.jpg\")\nstyle_image = scipy.misc.imread(\"images/my_style.jpg\")\n```\n1. 重新运行单元（你可能需要重新启动笔记本计算机上部选项卡中的Kernel ）。\n\n你还可以试着调整一下超参数：\n- 哪一层负责表示风格？ STYLE_LAYERS\n- 你要运行算法多少次迭代？ num_iterations\n- 内容和风格之间的相对权重是多少？ alpha / beta"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C2BE139184AD49A6965F64E19CEFEB76","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 6 总结\n\n恭喜你出色地完成这项任务！现在，你可以使用“神经风格迁移”生成艺术图像。这也是你第一次建立模型，在该模型中，优化算法将更新像素值而不是神经网络的参数。深度学习有许多不同类型的模型，这只是其中之一！\n\n你应该记住：\n- 神经风格迁移是一种算法，给定内容图像C和风格图像S可以生成艺术图像\n- 它使用基于预训练的ConvNet的特征（隐藏层激活）。\n- 使用一个隐藏层的激活来计算内容损失函数。\n- 使用该层激活的Gram矩阵计算一层的风格损失函数。使用几个隐藏层可以获得整体风格损失函数。\n- 优化总损失函数以合成新图像。\n\n"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"18858D5C78824DBB8D9E725EBCD2E213","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"\n这是本课程的最后编程练习。 恭喜，你已经完成了本课程在卷积网络上的所有编程练习！我们希望能在课程5-序列模型中同样看到你的身影。"},{"cell_type":"markdown","metadata":{"collapsed":true,"slideshow":{"slide_type":"slide"},"id":"3081CE271DF640118FE3C10A73E3DBBE","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"### 参考：\n\n神经风格迁移算法源于Gatys et al. (2015)。 Harish Narayanan和Github用户\"log0\"也写了很多精湛的文章，我们从中汲取了灵感。此实现中使用的预训练网络是VGG网络，这是Simonyan和Zisserman（2015）的工作成果。预先训练的权重来自MathConvNet团队的工作。\n\n- Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style (https://arxiv.org/abs/1508.06576) \n- Harish Narayanan, Convolutional neural networks for artistic style transfer. https://harishnarayanan.org/writing/artistic-style-transfer/\n- Log0, TensorFlow Implementation of \"A Neural Algorithm of Artistic Style\". http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n- Karen Simonyan and Andrew Zisserman (2015). Very deep convolutional networks for large-scale image recognition (https://arxiv.org/pdf/1409.1556.pdf)\n- MatConvNet. http://www.vlfeat.org/matconvnet/pretrained/\n\n"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}