{"cells":[{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"31D7360A652545489B49E9234A0F8120","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"# Keras教程 \n\n欢迎来到第2周的作业1。在此作业中，你将：\n1. 学习使用Keras，这是一种高级神经网络API（编程框架），采用Python编写，并且能够在包括TensorFlow和CNTK在内的几个较低级框架之上运行。\n1. 了解如何在几个小时内构建深度学习算法。\n\n我们为什么要使用Keras？开发Keras的目的是使深度学习工程师能够快速构建和试验不同的模型。正如TensorFlow是一个比Python更高级的框架一样，Keras是一个甚至更高层次的框架，能够以最小的延迟将想法付诸实践是找到良好模型的关键。但是，Keras比低级框架更具限制性，因此可以在TensorFlow中实现一些非常复杂的模型，而在Keras中实现这些模型较为困难。话虽如此，Keras仍可以在许多常见模型上正常工作。\n\n在本练习中，你将解决“the Happy House”问题，我们将在下面进行解释。首先让我们加载所需的软件包并开始解决问题吧！"},{"metadata":{"id":"CC61C50766194CDC89FFAAF68A4F1BD4","slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"/home/kesci/input/deeplearning72789\n","name":"stdout"}],"source":"cd ../input/deeplearning72789","execution_count":1},{"cell_type":"code","execution_count":2,"metadata":{"slideshow":{"slide_type":"slide"},"id":"A7BB84E62F6D48AF8D74EE34C0ABF0D0","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}],"source":"import numpy as np\n#import tensorflow as tf\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom kt_utils import *\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"52C4D5E1085847C4817BC221320813DC","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**注意**：如你所见，我们从Keras导入了许多函数。 你可以在笔记本中直接调用它们；\n例如：`X = Input（...）`或`X = ZeroPadding2D（...）`。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"38136ACEDB2B4B0980E67CDFE354591D","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 1 The Happy House 挑战 \n\n你决定与五个朋友在下个假期一起度过一星期。你们来到一个非常方便的房子，附近有很多事情可以做。但是最重要的好处是，每个人在家里时都承诺要快乐。因此，任何想要进入房屋的人都必须证明自己目前的幸福状态。\n作为一名深度学习专家，要确保严格执行“Happy”规则，你将要构建一种算法，该算法使用前门摄像头中的图片来检查该人是否快乐。仅当该人感到高兴时，门才应打开。\n\n你已经通过前门摄像头收集了你的朋友和你自己的照片。数据集是附带标签的。\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pydl2ibz.png?imageView2/0/w/960/h/960)\n\n运行以下代码以标准化数据集并查看其维度。"},{"cell_type":"code","execution_count":3,"metadata":{"slideshow":{"slide_type":"slide"},"id":"15F0C5108F0041DD899B07A019F0B832","collapsed":false,"scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"number of training examples = 600\nnumber of test examples = 150\nX_train shape: (600, 64, 64, 3)\nY_train shape: (600, 1)\nX_test shape: (150, 64, 64, 3)\nY_test shape: (150, 1)\n","name":"stdout"}],"source":"X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n\n# Normalize image vectors\nX_train = X_train_orig/255.\nX_test = X_test_orig/255.\n\n# Reshape\nY_train = Y_train_orig.T\nY_test = Y_test_orig.T\n\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"A8D47A394C044C3980402C9C2433AB1B","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**数据集的详细信息**：\n- 图像维度（64、64、3）\n- 训练：600张图片\n- 测试：150张图片\n\n现在该解决“Happy”挑战了。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"081730FA57F64E61B27B6B42C22EA394","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"## 2 在Keras中建立模型\n\nKeras非常适合快速制作原型，你可以在很短的时间内，建立一个能够获得出色结果的模型。\n\n这是Keras中的模型构建示例：\n\n```python\ndef model(input_shape):\n    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n    X_input = Input(input_shape)\n\n    # Zero-Padding: pads the border of X_input with zeroes\n    X = ZeroPadding2D((3, 3))(X_input)\n\n    # CONV -> BN -> RELU Block applied to X\n    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D((2, 2), name='max_pool')(X)\n\n    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n    X = Flatten()(X)\n    X = Dense(1, activation='sigmoid', name='fc')(X)\n\n    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n    \n    return model\n```\n\n请注意，Keras使用变量名与我们之前使用numpy和TensorFlow不同。不是在正向传播的每个步骤上创建和分配新变量，例如`X`, `Z1`, `A1`, `Z2`, `A2`等，以用于不同层的计算， Keras代码上面的每一行只是使用`X = ...`将`X`重新分配给新值。换句话说，在正向传播的每个步骤中，我们只是将计算中的最新值写入相同的变量`X`。唯一的例外是`X_input`，我们将其分开并没有覆盖，因为我们最终需要它来创建Keras模型实例（上面的`model = Model(inputs = X_input, ...)`）。\n\n**练习**：实现一个`HappyModel（）`。我们建议你首先使用我们建议的结构来实现模型，然后再使用该模型作为初始模型来完成本任务的其余部分。之后请返回并主动尝试其他模型架构。例如，你可能会从上面的模型中获得启发，但是随后根据需要更改网络体系结构和超参数。你还可以使用其他函数，例如`AveragePooling2D()`, `GlobalMaxPooling2D()`, `Dropout()`。\n\n**注意**：注意数据的维度。利用你在视频中学到的知识，确保卷积，池化和全连接层适用。"},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"33CBD8D1A6014BCFABA02DBA978C3259","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: HappyModel\n\ndef HappyModel(input_shape):\n    \"\"\"\n    Implementation of the HappyModel.\n    \n    Arguments:\n    input_shape -- shape of the images of the dataset\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    ### START CODE HERE ###\n    # Feel free to use the suggested outline in the text above to get started, and run through the whole\n    # exercise (including the later portions of this notebook) once. The come back also try out other\n    # network architectures as well. \n    X_input = Input(shape=input_shape)\n    X = ZeroPadding2D(padding=(1, 1))(X_input)\n    X = Conv2D(8, kernel_size=(3,3), strides=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)\n    \n    X = ZeroPadding2D(padding=(1, 1))(X)\n    X = Conv2D(16, kernel_size=(3,3), strides=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)\n    \n    X = ZeroPadding2D(padding=(1, 1))(X)\n    X = Conv2D(32, kernel_size=(3,3), strides=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(X)\n    \n    # FC\n    X = Flatten()(X)\n    Y = Dense(1, activation='sigmoid')(X)\n    \n    model = Model(inputs = X_input, outputs = Y, name='HappyModel')\n    ### END CODE HERE ###\n    \n    return model"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"2F8C70C271004C6F85C05D4B43A32D0E","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"现在，你已经构建了一个描述模型的函数。为了训练和测试该模型，Keras中有四个步骤：\n\n1. 通过调用上面的函数创建模型\n1. 通过调用`model.compile(optimizer = \"...\", loss = \"...\", metrics = [\"accuracy\"])`编译模型\n1. 通过调用`model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)`训练模型\n1. 通过调用`model.evaluate(x = ..., y = ...)`测试模型\n\n如果你想进一步了解`model.compile（）`，`model.fit（）`，`model.evaluate（）`及其参数，请参考官方 [Keras documentation](https://keras.io/models/model/)\n\n**练习**：第一步，创建模型"},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"80FFA982B0D74AC88E655DCA36D1E8C8","scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}],"source":"### START CODE HERE ### (1 line)\nhappyModel = HappyModel((64, 64, 3))\n### END CODE HERE ###"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"2A0C0FA894C040219878545E13BD3ED3","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**练习**：实施第2步，编译模型以配置学习过程。 正确选择 `compile()`的3个参数。\n提示：“快乐挑战”是一个二进制分类问题。"},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"DC79B63DB98E42E8B1834D3E906A3B04","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"### START CODE HERE ### (1 line)\nimport keras\nhappyModel.compile(optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss='binary_crossentropy', metrics=['accuracy'])\n### END CODE HERE ###"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"B10A46356FE647D78D1347FC0D7D1429","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**练习**：实施第3步，训练模型。选择epoch和批次大小。"},{"cell_type":"code","execution_count":7,"metadata":{"slideshow":{"slide_type":"slide"},"id":"CC1639808C474B6A85A7209CC17E4CB4","collapsed":false,"scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/20\n600/600 [==============================] - 6s 10ms/step - loss: 0.5211 - acc: 0.7517\nEpoch 2/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.2041 - acc: 0.9483\nEpoch 3/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.1337 - acc: 0.9683\nEpoch 4/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.1115 - acc: 0.9750\nEpoch 5/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0845 - acc: 0.9767\nEpoch 6/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0650 - acc: 0.9850\nEpoch 7/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0512 - acc: 0.9833\nEpoch 8/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0394 - acc: 0.9917\nEpoch 9/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0349 - acc: 0.9967\nEpoch 10/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0292 - acc: 0.9983\nEpoch 11/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0233 - acc: 0.9983\nEpoch 12/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0200 - acc: 0.9967\nEpoch 13/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0223 - acc: 0.9967\nEpoch 14/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0178 - acc: 0.9967\nEpoch 15/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0131 - acc: 0.9983\nEpoch 16/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0114 - acc: 1.0000\nEpoch 17/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0114 - acc: 0.9983\nEpoch 18/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0101 - acc: 0.9983\nEpoch 19/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0089 - acc: 1.0000\nEpoch 20/20\n600/600 [==============================] - 5s 9ms/step - loss: 0.0065 - acc: 1.0000\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<keras.callbacks.History at 0x7f9dcc404d68>"},"transient":{},"execution_count":7}],"source":"### START CODE HERE ### (1 line)\nhappyModel.fit(x=X_train, y=Y_train, batch_size=16, epochs=20)\n### END CODE HERE ###"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"83540E9747484CD3B31BEFD23264546F","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"请注意，如果再次运行`fit()`，`model`将继续使用已经学习的参数进行训练，而不是重新初始化它们。\n\n**练习**：实施第4步，测试/评估模型。"},{"cell_type":"code","execution_count":8,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"A1C4ACDD9955430A9D2D3D9782BC0330","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"150/150 [==============================] - 1s 4ms/step\n\nLoss = 0.10092398126920064\nTest Accuracy = 0.9533333373069763\n","name":"stdout"}],"source":"### START CODE HERE ### (1 line)\npreds = happyModel.evaluate(x=X_test, y=Y_test)\n### END CODE HERE ###\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"5E65C4E8AC4640B6AD9C84F3F8432157","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"如果你的`happyModel()`函数起作用，在训练和测试集上的测试结果应该比随机猜测（50％）更好。要通过此作业，你必须至少达到75％的准确性。\n\n为了给你提供一个比较点，我们的模型在batch size为16个和adam优化器的情况下，在40个epoch内获得了95％的测试准确度（和99％的训练准确度）。但是我们的模型仅需2-5个epoch即可获得不错的准确性，因此，如果你要比较不同的模型，则还可以在几个epoch上训练各种模型，并观察比较它们。\n\n如果你尚未达到75％的准确度，可以尝试以下方法来达到此目的：\n\n- 尝试使用CONV-> BATCHNORM-> RELU模块，例如：\n```python\nX = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\nX = BatchNormalization(axis = 3, name = 'bn0')(X)\nX = Activation('relu')(X)\n```\n- 你可以在此模块之后使用MAXPOOL。这将帮助你降低高度和宽度尺寸。\n- 更改优化器。我们发现Adam行之有效。\n- 如果模型运行困难，并且遇到内存问题，请降低batch_size（例如12）\n- 运行更多epoch，直到看到训练精度达到稳定。\n\n即使你已达到75％的准确性，也可以调整模型，尝试获得更好的结果。\n\n**注意**：如果你调整模型超参数，则测试集实际上将成为开发集，并且你的模型最终可能会过拟合测试（开发）集。但仅出于此作业的目的，我们在此无需担心。\n"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"1BFFD64DA63F4777920F76D26FCDA300","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"## 3 结论\n\nNice，你已经解决了快乐之家的挑战！\n\n现在，你只需要将此模型连接到房屋的前门摄像头即可。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"F6DE1F6A9D5A41CB9160BA14E2A7943E","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**我们希望你从这项作业中记住什么：**\n- Keras是我们建议用于快速制作模型的工具。它使你可以快速尝试不同的模型架构。你有想用Keras实现日常生活中任何深度学习的应用吗？\n- 记住如何在Keras中编码模型以及完成在测试集上评估模型的四个步骤。创建->编译->调整/训练->评估/测试。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"BE398C05C2C345F485201E3469DF8708","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 4 使用你自己的图像进行测试（可选）\n\n祝贺你完成此作业。现在，你可以拍张照片，看看是否可以进入快乐之家。要做到这一点：\n     1.单击此笔记本上部栏中的\"File\"，然后单击\"Open\"以在Coursera Hub上运行。\n     2.将图像添加到Jupyter Notebook的目录中，在\"images\"文件夹中\n     3.在以下代码中写下你的图片名称\n     4.运行代码并检查算法是否正确（0表示unhappy，1表示happy）！\n    \n训练/测试集非常相似。例如，所有图片都是在相同背景下拍摄的（因为前门摄像头始终安装在同一位置）。这使问题变得更容易，但是根据该数据训练的模型也可能无法在你自己的数据上工作。但是，可以尝试一下！"},{"cell_type":"code","execution_count":11,"metadata":{"slideshow":{"slide_type":"slide"},"id":"786EB8642D7C4E628E99B1BEDF5293E9","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"[[1.]]\n","name":"stdout"},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/786EB8642D7C4E628E99B1BEDF5293E9/q1pyka8cbp.png\">"},"transient":{}}],"source":"### START CODE HERE ###\nimg_path = 'my_image.jpg'\n### END CODE HERE ###\nimg = image.load_img(img_path, target_size=(64, 64))\nimshow(img)\n\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nprint(happyModel.predict(x))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"89F49067329B4DEE94FA1F10C91B5813","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 5 Keras中的其他有用函数（可选）\n\n你会发现Keras中其他两个有用的基本功能是：\n- `model.summary()`：以表格形式打印每层输入输出的详细信息\n- `plot_model()`：绘制图形，如果你想在社交媒体上共享它，可以使用SVG（）将其另存为“ .png”，它保存在笔记本计算机上方栏中的\"File\"然后\"Open...\" 中。\n\n运行以下代码。"},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"11028CDB939C462F87022AEB1EED4E33","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 64, 64, 3)         0         \n_________________________________________________________________\nzero_padding2d_1 (ZeroPaddin (None, 66, 66, 3)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 64, 64, 8)         224       \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 64, 64, 8)         32        \n_________________________________________________________________\nactivation_1 (Activation)    (None, 64, 64, 8)         0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 32, 32, 8)         0         \n_________________________________________________________________\nzero_padding2d_2 (ZeroPaddin (None, 34, 34, 8)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 16)        1168      \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 32, 32, 16)        64        \n_________________________________________________________________\nactivation_2 (Activation)    (None, 32, 32, 16)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 16, 16, 16)        0         \n_________________________________________________________________\nzero_padding2d_3 (ZeroPaddin (None, 18, 18, 16)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 32)        4640      \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 16, 16, 32)        128       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 16, 16, 32)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 2048)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 2049      \n=================================================================\nTotal params: 8,305\nTrainable params: 8,193\nNon-trainable params: 112\n_________________________________________________________________\n","name":"stdout"}],"source":"happyModel.summary()"},{"cell_type":"code","execution_count":13,"metadata":{"slideshow":{"slide_type":"slide"},"id":"BE51D35845A94469B4EE7BD371900E27","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<IPython.core.display.SVG object>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/BE51D35845A94469B4EE7BD371900E27/q1pykidqri.svg\">"},"transient":{},"execution_count":13}],"source":"plot_model(happyModel, to_file='HappyModel.png')\nSVG(model_to_dot(happyModel).create(prog='dot', format='svg'))"},{"metadata":{"id":"1D95F2373FE64D7E81F6223F855686AF","slideshow":{"slide_type":"slide"},"jupyter":{},"tags":[],"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}