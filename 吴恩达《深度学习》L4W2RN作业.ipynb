{"cells":[{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"14F0F017612848F98821378B7A37364D","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"# 残差网络\n欢迎来到本周的第二项作业！你将学习如何使用残差网络（ResNets）构建非常深的卷积网络。理论上讲，更深的网络可以表现更复杂的特征。但实际上，它们很难训练。[He et al.](https://arxiv.org/pdf/1512.03385.pdf)引入的残差网络使你可以训练比以前实际可行的深层网络。\n\n**在此作业中，你将：**\n- 实现ResNets的基本构建块。\n- 将这些模块放在一起，以实现和训练用于图像分类的最新神经网络。\n\n这项作业将使用Keras完成。\n\n在跳入问题之前，让我们运行下面的单元格以加载所需的包。"},{"metadata":{"id":"452CE645F0BF4B1084EFF757F5C8A6BB","slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"/home/kesci/input/deeplearning86820\n","name":"stdout"}],"source":"cd /home/kesci/input/deeplearning86820","execution_count":4},{"cell_type":"code","execution_count":5,"metadata":{"slideshow":{"slide_type":"slide"},"id":"020F904C7FEB4DCB8BA6F9B0119372FD","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"import numpy as np\nimport tensorflow as tf\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom resnets_utils import *\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"8E6D1AE5351F489C8E1275026427F9BB","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 1 深层神经网络带来的问题\n\n上周，你构建了第一个卷积神经网络。近年来，神经网络变得越来越深，网络已经从最初的几层（例如AlexNet）扩展到了一百多层。\n\n深层网络的主要好处是可以表示非常复杂的特征。它还可以学习许多不同抽象级别的特征，从边缘（较低层）到非常复杂的特征（较深层）。但是，使用更深的网络并不总是好的。训练它们的一个巨大障碍是梯度的消失：非常深的网络通常具有迅速变为零的梯度信号，因此使梯度下降的速度令人难以忍受。更具体地说，在梯度下降过程中，当你从最后一层反向传播回第一层时，你需要在每一步上乘以权重矩阵，因此，梯度可以快速指数下降至零（或者在极少数情况下呈指数增长并“爆炸”为非常大的值）。\n\n因此，在训练过程中，随着训练的进行，你可能会看到较早层的梯度的大小（或范数）非常快地减小到零："},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C894DF386A9343D6AF6D27C61F612793","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/q1pyvtcil.png?imageView2/0/w/960/h/960)\n\n\n**图1 **：**梯度消失**\n\n随着训练，网络学习的速度开始迅速下降\n你现在将通过构建残差网络来解决此问题！"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"3B0DF534EAE14351AFC18EA9F38EB059","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 2 建立残差网络\n\n在ResNets中，\"shortcut\" 或者 \"skip connection\"允许将梯度直接反向传播到较早的层：\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pywrtg4.png?imageView2/0/w/960/h/960)\n\n**图2**：显示**skip connection**的残差块\n\n左图显示了通过网络的“主要路径”。右图为主路径添加了shortcut。通过将这些ResNet块彼此堆叠，可以形成一个非常深的网络。\n\n我们在教程中还看到，使用带有shortcut的ResNet块可以非常容易学习标识功能。这意味着你可以堆叠在其他ResNet块上，而几乎不会损害训练集性能。（还有一些证据表明，学习标识功能甚至比skip connections有助于解决梯度消失问题--也说明了ResNets的出色性能。）\n\nResNet中主要使用两种类型的块，这主要取决于输入/输出尺寸是相同还是不同。你将要在作业中实现两者。\n"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"B3B73FA2816840CE8A52FFD173D8B52D","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"### 2.1 The identity block\n\nThe identity block是ResNets中使用的标准块，它对应于输入激活（例如$a^{[l]}$）与输出激活（例如$a^{[l+2]}$）。为了充实ResNet标识块中发生的不同步骤，下面是显示各个步骤的替代图：\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pyxyhn0z.png?imageView2/0/w/960/h/960)\n\n**图3 **：**标识块** skips over2层\n\n上部路径是“shortcut path”。下部路径是“main path”。在此图中，我们还明确了每一层中的CONV2D和ReLU步骤。为了加快训练速度，我们还添加了BatchNorm步骤。不必担心实现起来很复杂-你会看到BatchNorm只需Keras中的一行代码！\n\n在本练习中，你实际上将实现此识别块的功能稍强的版本，其中跳过连接将\"skips over\"3个隐藏层而不是2个。看起来像这样：\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pyyholx6.png?imageView2/0/w/960/h/960)\n\n**图4 **：**标识块** skips over3层。\n\n下面是各个步骤：\n\n主路径的第一部分：\n- 第一个CONV2D具有形状为（1,1）和步幅为（1,1）的$F_1$个滤波器。其填充为“valid”，其名称应为`conv_name_base + '2a'`。使用0作为随机初始化的种子。\n- 第一个BatchNorm标准化通道轴。它的名字应该是`bn_name_base + '2a'`。\n- 然后应用ReLU激活函数。\n\n主路径的第二部分：\n- 第二个CONV2D具有形状为$(f,f)$ 的步幅为（1,1）的$F_2$个滤波器。其填充为“same”，其名称应为`conv_name_base + '2b'`。使用0作为随机初始化的种子。\n- 第二个BatchNorm标准化通道轴。它的名字应该是`bn_name_base + '2b'`。\n- 然后应用ReLU激活函数。\n\n主路径的第三部分：\n- 第三个CONV2D具有形状为（1,1）和步幅为（1,1）的$F_3$个滤波器。其填充为“valid”，其名称应为`conv_name_base + '2c'`。使用0作为随机初始化的种子。\n- 第三个BatchNorm标准化通道轴。它的名字应该是`bn_name_base + '2c'`。请注意，此组件中没有ReLU激活函数。\n\n最后一步：\n- 将shortcut和输入添加在一起。\n- 然后应用ReLU激活函数。\n\n**练习**：实现ResNet的identity block。我们已经实现了主路径的第一部分，请仔细阅读此内容，以确保你知道它在做什么。你应该执行其余的工作。\n- 要实现Conv2D步骤：[See reference](https://keras.io/layers/convolutional/#conv2d)\n- 要实现BatchNorm： [See reference](https://faroit.github.io/keras-docs/1.2.2/layers/normalization/)（axis：整数，需要标准化的轴（通常是通道轴） ）\n- 对于激活，请使用：`Activation('relu')(X)`\n- 要添加shortcut传递的值：[See reference](https://keras.io/layers/merge/#add)"},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"450A36C644E54C86A977D3A5F1CEB3FC","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: identity_block\n\ndef identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Implementation of the identity block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE ###\n    \n    # Second component of main path (≈3 lines)\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (≈2 lines)\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = layers.add([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X"},{"cell_type":"code","execution_count":7,"metadata":{"slideshow":{"slide_type":"slide"},"id":"E068A528E77E427B8DE7C2E37E97058F","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nout = [0.19716819 0.         1.3561226  2.1713073  0.         1.3324987 ]\n","name":"stdout"}],"source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    np.random.seed(1)\n    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n    X = np.random.randn(3, 4, 4, 6)\n    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n    test.run(tf.global_variables_initializer())\n    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n    print(\"out = \" + str(out[0][1][1][0]))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"DF4189CB8E7C4A098296E45BDF35C5BA","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nout = [0.19716819 0.         1.3561226  2.1713073  0.         1.3324987 ]"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C5A6A0831445418EB3C59D003EA85F7A","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"### 2.2 The convolutional block\n\n你已经实现了ResNet中的识别块。接下来，ResNet“卷积块”是另一种类型的块。当输入和输出尺寸不匹配时，可以使用这种类型的块。与标识块的区别在于，shortcut路径中有一个CONV2D层：\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pyzyp0ik.png?imageView2/0/w/960/h/960)\n\n**图4 **：**卷积块**\n\nshortcut路径中的CONV2D层用于将输入$x$调整为另一个维度的大小，以便维度与最终需要添加到shortcut主路径所用的维度匹配。（这与讲座中讨论的矩阵$W_s$起到类似的作用。）例如，要将激活尺寸的高度和宽度减小2倍，可以使用步幅为2的1x1卷积。CONV2D层位于shortcut路径不使用任何非线性激活函数。它的主要作用是仅应用（学习的）线性函数来减小输入的维度，以使维度与之后的步骤匹配。\n\n卷积块的细节如下：\n\n主路径的第一部分：\n- 第一个CONV2D具有形状为（1,1）和步幅为（s，s）的$F_1$个滤波器。其填充为\"valid\"，其名称应为`conv_name_base + '2a'`。\n- 第一个BatchNorm标准化通道轴。其名字是`bn_name_base + '2a'`。\n- 然后应用ReLU激活函数。\n\n主路径的第二部分：\n- 第二个CONV2D具有（f，f）的$F_2$滤波器和（1,1）的步幅。其填充为\"same\"，并且名称应为`conv_name_base + '2b'`。\n- 第二个BatchNorm标准化通道轴。它的名字应该是`bn_name_base + '2b'`。\n- 然后应用ReLU激活函数。\n\n主路径的第三部分：\n- 第三个CONV2D的$F_3$滤波器为（1,1），步幅为（1,1）。其填充为\"valid\"，其名称应为`conv_name_base + '2c'`。\n- 第三个BatchNorm标准化通道轴。它的名字应该是`bn_name_base + '2c'`。请注意，此组件中没有ReLU激活函数。\n\nShortcut path：\n- CONV2D具有形状为（1,1）和步幅为（s，s）的$F_3$个滤波器。其填充为\"valid\"，其名称应为`conv_name_base + '1'`。\n- BatchNorm标准化通道轴。它的名字应该是`bn_name_base + '1'`。\n\n最后一步：\n- 将Shortcut路径和主路径添加在一起。\n- 然后应用ReLU激活函数。\n\n    \n\n\n**练习**：实现卷积模块。我们已经实现了主路径的第一部分；你应该执行其余的工作。和之前一样，使用0作为随机初始化的种子，以确保与评分器的一致性。\n- [Conv Hint](https://keras.io/layers/convolutional/#conv2d)\n- [BatchNorm Hint](https://keras.io/layers/normalization/#batchnormalization) （axis：整数，需要标准化的轴（通常是特征轴））\n- 激活函数请使用：`Activation('relu')(X)`\n- [Addition Hint](https://keras.io/layers/merge/#add)\n"},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"F7D4D7A63C3146CC88BF643CF4091BFE","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: convolutional_block\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"\n    Implementation of the convolutional block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    ### START CODE HERE ###\n\n    # Second component of main path (≈3 lines)\n    X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + '2b',padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (≈2 lines)\n    X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + '2c',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH #### (≈2 lines)\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), name = conv_name_base + '1',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = layers.add([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X"},{"cell_type":"code","execution_count":9,"metadata":{"slideshow":{"slide_type":"slide"},"id":"43A2D69EC6834AA18879E47AC8A7129D","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"out = [0.09018463 1.2348979  0.46822023 0.03671762 0.         0.65516603]\n","name":"stdout"}],"source":"tf.reset_default_graph()\n\nwith tf.Session() as test:\n    np.random.seed(1)\n    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n    X = np.random.randn(3, 4, 4, 6)\n    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n    test.run(tf.global_variables_initializer())\n    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n    print(\"out = \" + str(out[0][1][1][0]))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"CE8CA7726E3B46119FB5ECC1D942B6CF","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nout = [0.09018463 1.2348979  0.46822023 0.03671762 0.         0.65516603]"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"13B0F6A2457C4D8EBDAA787161544087","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"## 3 建立你的第一个ResNet模型（50层）\n\n现在，你具有构建非常深的ResNet的必要块。下图详细描述了此神经网络的体系结构。图中的“ID BLOCK”代表“识别块”，“ID BLOCK x3”表示你应该将3个识别块堆叠在一起。\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pz1253ll.png?imageView2/0/w/960/h/960)\n\n**图5 **：**ResNet50 模型**\n\n此ResNet-50模型的详细结构是：\n\n- 零填充填充（3,3）的输入\n- 阶段1：\n    - 2D卷积具有64个形状为（7,7）的滤波器，并使用（2,2）步幅，名称是“conv1”。\n    - BatchNorm应用于输入的通道轴。\n    - MaxPooling使用（3,3）窗口和（2,2）步幅。\n- 阶段2：\n    - 卷积块使用三组大小为[64,64,256]的滤波器，“f”为3，“s”为1，块为“a”。\n    - 2个标识块使用三组大小为[64,64,256]的滤波器，“f”为3，块为“b”和“c”。\n- 阶段3：\n    - 卷积块使用三组大小为[128,128,512]的滤波器，“f”为3，“s”为2，块为“a”。\n    - 3个标识块使用三组大小为[128,128,512]的滤波器，“f”为3，块为“b”，“c”和“d”。\n- 阶段4：\n    - 卷积块使用三组大小为[256、256、1024]的滤波器，“f”为3，“s”为2，块为“a”。\n    - 5个标识块使用三组大小为[256、256、1024]的滤波器，“f”为3，块为“b”，“c”，“d”，“e”和“f”。\n- 阶段5：\n    - 卷积块使用三组大小为[512、512、2048]的滤波器，“f”为3，“s”为2，块为“a”。\n    - 2个标识块使用三组大小为[256、256、2048]的滤波器，“f”为3，块为“b”和“c”。\n- 2D平均池使用形状为（2,2）的窗口，其名称为“avg_pool”。\n- Flatten层没有任何超参数或名称。\n- 全连接（密集）层使用softmax激活将其输入减少为类数。名字是`'fc' + str(classes)`。\n\n**练习**：使用上图中的描述实现50层的ResNet。我们已经执行了第一阶段和第二阶段。请执行其余的步骤。（实现阶段3-5的语法应与阶段2的语法相似）请确保遵循上面文本中的命名。\n\n你需要使用以下函数：\n- Average pooling [see reference](https://keras.io/layers/pooling/#averagepooling2d)\n\n这是我们在以下代码中使用的其他函数：\n- Conv2D: [See reference](https://keras.io/layers/convolutional/#conv2d)\n- BatchNorm: [See reference](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n- Zero padding: [See reference](https://keras.io/layers/convolutional/#zeropadding2d)\n- Max pooling: [See reference](https://keras.io/layers/pooling/#maxpooling2d)\n- Fully conected layer: [See reference](https://keras.io/layers/core/#dense)\n- Addition: [See reference](https://keras.io/layers/merge/#add)\n"},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"A569310D9C8F4DB99DF0B998B28312F9","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# GRADED FUNCTION: ResNet50\n\ndef ResNet50(input_shape = (64, 64, 3), classes = 6):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    ### START CODE HERE ###\n\n    # Stage 3 (≈4 lines)\n    # The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n    # The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n    X = convolutional_block(X, f = 3, filters=[128,128,512], stage = 3, block='a', s = 2)\n    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='b')\n    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='c')\n    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='d')\n\n    # Stage 4 (≈6 lines)\n    # The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n    # The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n    X = convolutional_block(X, f = 3, filters=[256, 256, 1024], block='a', stage=4, s = 2)\n    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='b', stage=4)\n    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='c', stage=4)\n    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='d', stage=4)\n    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='e', stage=4)\n    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='f', stage=4)\n\n    # Stage 5 (≈3 lines)\n    # The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n    # The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n    X = convolutional_block(X, f = 3, filters=[512, 512, 2048], stage=5, block='a', s = 2)\n    \n    # filters should be [256, 256, 2048], but it fail to be graded. Use [512, 512, 2048] to pass the grading\n    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='b')\n    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='c')\n\n    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n    # The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n    X = AveragePooling2D(pool_size=(2,2))(X)\n    \n    ### END CODE HERE ###\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"A7EA382842DC4019928E54051413A136","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"运行以下代码以构建模型图。如果你的实现不正确，则可以通过运行下面的`model.fit（...）`时检查准确性"},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"3E45F79E85BE41C5ACF8B0757984F7CD","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"model = ResNet50(input_shape = (64, 64, 3), classes = 6)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"D29245BFCAF449478D88F067499DC626","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"如在Keras教程笔记本中所见，在训练模型之前，你需要通过编译模型来配置学习过程。"},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"},"id":"C3FD57E870D74F5A8FF9BCD6206008BB","scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"1599C4238F424D0DAC927922E4BC8C5A","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"现在可以训练模型了。 你唯一需要的就是数据集。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"EC0055B04B2C482BB51EF98A944579EC","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"加载SIGNS数据集。\n\n![Image Name](https://cdn.kesci.com/upload/image/q1pz2akjjm.png?imageView2/0/w/960/h/960)\n\n**图6 **：**SIGNS 数据集**"},{"cell_type":"code","execution_count":13,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"4EA02DFC78D747A8974F4C1C86D7B3CF","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"number of training examples = 1080\nnumber of test examples = 120\nX_train shape: (1080, 64, 64, 3)\nY_train shape: (1080, 6)\nX_test shape: (120, 64, 64, 3)\nY_test shape: (120, 6)\n","name":"stdout"}],"source":"X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n\n# Normalize image vectors\nX_train = X_train_orig/255.\nX_test = X_test_orig/255.\n\n# Convert training and test labels to one hot matrices\nY_train = convert_to_one_hot(Y_train_orig, 6).T\nY_test = convert_to_one_hot(Y_test_orig, 6).T\n\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"3021F833C72C427B9C28FF03C960A178","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"运行以下单元格，训练模型（批处理大小为32）2个epoch。在CPU上，每个epoch大约需要5分钟。"},{"cell_type":"code","execution_count":14,"metadata":{"scrolled":true,"slideshow":{"slide_type":"slide"},"id":"ACC2E79B44EC493383E74D3FBC53D1F1","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/20\n1080/1080 [==============================] - 198s 183ms/step - loss: 2.7697 - acc: 0.2880\nEpoch 2/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 1.8029 - acc: 0.4815\nEpoch 3/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 1.2630 - acc: 0.6398\nEpoch 4/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.8306 - acc: 0.7657\nEpoch 5/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 1.0470 - acc: 0.7231\nEpoch 6/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.7639 - acc: 0.8185\nEpoch 7/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.5335 - acc: 0.9083\nEpoch 8/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.5189 - acc: 0.9204\nEpoch 9/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.7759 - acc: 0.8620\nEpoch 10/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 1.3442 - acc: 0.5750\nEpoch 11/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.5672 - acc: 0.7861\nEpoch 12/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.3369 - acc: 0.8843\nEpoch 13/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.2433 - acc: 0.9185\nEpoch 14/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.1352 - acc: 0.9537\nEpoch 15/20\n1080/1080 [==============================] - 188s 174ms/step - loss: 0.1032 - acc: 0.9630\nEpoch 16/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.0695 - acc: 0.9759\nEpoch 17/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.0814 - acc: 0.9741\nEpoch 18/20\n1080/1080 [==============================] - 187s 174ms/step - loss: 0.0642 - acc: 0.9741\nEpoch 19/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.0632 - acc: 0.9787\nEpoch 20/20\n1080/1080 [==============================] - 186s 173ms/step - loss: 0.1022 - acc: 0.9630\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<keras.callbacks.History at 0x7f1bc06eecc0>"},"transient":{},"execution_count":14}],"source":"model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"B1BDC104FC0848028BD804C25CC474CB","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**Expected Output**:\nEpoch 1/20\n1080/1080 [==============================] - 198s 183ms/step - loss: 2.7697 - acc: 0.2880\nEpoch 2/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 1.8029 - acc: 0.4815\n...\nEpoch 19/20\n1080/1080 [==============================] - 187s 173ms/step - loss: 0.0632 - acc: 0.9787\nEpoch 20/20\n1080/1080 [==============================] - 186s 173ms/step - loss: 0.1022 - acc: 0.9630"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"D32C3A9BBD11400289EA06BF86EFC238","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"让我们看看这个模型（仅在训练了2个epoch）在测试集上的表现。"},{"cell_type":"code","execution_count":15,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"773E946ED26A44B9842C18CA242850CA","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"120/120 [==============================] - 6s 47ms/step\nLoss = 0.47188322941462196\nTest Accuracy = 0.8916666626930236\n","name":"stdout"}],"source":"preds = model.evaluate(X_test, Y_test)\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"F7BD7D7E479146CBB1DF0389DA094CCC","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**预期输出**:\nLoss = 0.47188322941462196\nTest Accuracy = 0.8916666626930236"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"2B0AE9713BDE47E4B5700347C1530BF3","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"为了完成这项作业，我们已要求你仅在两个epoch内训练模型。尽管它表现不佳，也请继续提交作业； 为了检查正确性，在线评分器也将仅在几个epoch内运行你的代码。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"73B81EFEB6FA4A5197455DC6866B2FAC","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"### 示例训练模型（未提供）\n完成此任务的正式（分级）部分后，如果需要，你还可以选择训练ResNet进行更多epoch。训练约20个epoch时，我们会获得更好的性能，但是在CPU上进行训练将需要一个多小时。\n\n使用GPU，我们已经在SIGNS数据集上训练了自己的ResNet50模型的权重。你可以在下面的单元格中的测试集上加载并运行我们训练好的模型。加载模型可能需要大约1分钟。"},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":true,"slideshow":{"slide_type":"slide"},"id":"F2994DC33FAD42368313E4E22CA30A62","jupyter":{},"tags":[],"trusted":true},"outputs":[],"source":"# model = load_model('ResNet50.h5') #这里要读模型，我们可以先沿用老的模型"},{"cell_type":"code","execution_count":16,"metadata":{"scrolled":false,"slideshow":{"slide_type":"slide"},"id":"7CC927C511434610A21424E18EC438D7","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"120/120 [==============================] - 4s 37ms/step\nLoss = 0.47188322941462196\nTest Accuracy = 0.8916666626930236\n","name":"stdout"}],"source":"preds = model.evaluate(X_test, Y_test)\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"502E49A0757041A582CCC3903376AE39","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"如果对ResNet50进行足够数量的迭代训练，则它将是用于图像分类的强大模型。我们希望你可以使用所学的知识并将其应用于你自己的分类问题，以实现最新的准确性。\n\n恭喜你完成此作业！你现在已经实现了一个优异的图像分类系统！"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"6FC383FE7EE048FDBF8BE8D997C5926C","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"## 4 测试你自己的图片（可选练习）"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"86B1EED718CF40E48F28E5560E7A1878","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"如果愿意，你也可以拍自己的手的照片并查看模型的输出。 你可以：\n1.      单击此笔记本上部栏中的\"File\"，然后单击\"Open\"以在Coursera Hub上运行。\n1.      将图像添加到Jupyter Notebook的目录中，在\"images\"文件夹中\n1.      在以下代码中写下你的图片名称\n1.      运行代码，然后检查算法是否正确！"},{"cell_type":"code","execution_count":17,"metadata":{"slideshow":{"slide_type":"slide"},"id":"2A4C6F01571A4AE1863E061FC2D5620B","collapsed":false,"scrolled":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"Input image shape: (1, 64, 64, 3)\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\nUse ``imageio.imread`` instead.\n  import sys\n","name":"stderr"},{"output_type":"stream","text":"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \n[[1. 0. 0. 0. 0. 0.]]\n","name":"stdout"},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/2A4C6F01571A4AE1863E061FC2D5620B/q1q2mdphqd.png\">"},"transient":{}}],"source":"img_path = 'my_image.jpg'\nimg = image.load_img(img_path, target_size=(64, 64))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nprint('Input image shape:', x.shape)\nmy_image = scipy.misc.imread(img_path)\nimshow(my_image)\nprint(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\nprint(model.predict(x))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"90B2E358EF48406B92B54A92D5FC3096","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"你还可以通过运行以下代码来打印模型的摘要。"},{"cell_type":"code","execution_count":18,"metadata":{"scrolled":true,"slideshow":{"slide_type":"slide"},"id":"339CA46215F949EA83B6C4E15DE52BBB","collapsed":false,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n__________________________________________________________________________________________________\nzero_padding2d_1 (ZeroPadding2D (None, 70, 70, 3)    0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d_1[0][0]           \n__________________________________________________________________________________________________\nbn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 64)   0           activation_4[0][0]               \n__________________________________________________________________________________________________\nres2a_branch2a (Conv2D)         (None, 15, 15, 64)   4160        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbn2a_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 15, 15, 64)   0           bn2a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2a_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_5[0][0]               \n__________________________________________________________________________________________________\nbn2a_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 15, 15, 64)   0           bn2a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2a_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_6[0][0]               \n__________________________________________________________________________________________________\nres2a_branch1 (Conv2D)          (None, 15, 15, 256)  16640       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbn2a_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn2a_branch1 (BatchNormalizatio (None, 15, 15, 256)  1024        res2a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 15, 15, 256)  0           bn2a_branch2c[0][0]              \n                                                                 bn2a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 15, 15, 256)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nres2b_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_7[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 15, 15, 64)   0           bn2b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2b_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_8[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 15, 15, 64)   0           bn2b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2b_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_9[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 15, 15, 256)  0           bn2b_branch2c[0][0]              \n                                                                 activation_7[0][0]               \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 15, 15, 256)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nres2c_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_10[0][0]              \n__________________________________________________________________________________________________\nbn2c_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 15, 15, 64)   0           bn2c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2c_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_11[0][0]              \n__________________________________________________________________________________________________\nbn2c_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 15, 15, 64)   0           bn2c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2c_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_12[0][0]              \n__________________________________________________________________________________________________\nbn2c_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 15, 15, 256)  0           bn2c_branch2c[0][0]              \n                                                                 activation_10[0][0]              \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 15, 15, 256)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nres3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_13[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_14[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_15[0][0]              \n__________________________________________________________________________________________________\nres3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_13[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n                                                                 bn3a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n__________________________________________________________________________________________________\nres3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_16[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_17[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_18[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n                                                                 activation_16[0][0]              \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 8, 8, 512)    0           add_6[0][0]                      \n__________________________________________________________________________________________________\nres3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_19[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_20[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_21[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n                                                                 activation_19[0][0]              \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 8, 8, 512)    0           add_7[0][0]                      \n__________________________________________________________________________________________________\nres3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_22[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_23[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_24[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n                                                                 activation_22[0][0]              \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 8, 8, 512)    0           add_8[0][0]                      \n__________________________________________________________________________________________________\nres4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_25[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_26[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_27[0][0]              \n__________________________________________________________________________________________________\nres4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_25[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n                                                                 bn4a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 4, 4, 1024)   0           add_9[0][0]                      \n__________________________________________________________________________________________________\nres4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_28[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_29[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_30[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n                                                                 activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 4, 4, 1024)   0           add_10[0][0]                     \n__________________________________________________________________________________________________\nres4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_31[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_32[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_33[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n__________________________________________________________________________________________________\nres4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_34[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_35[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_36[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n__________________________________________________________________________________________________\nres4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_37[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_38[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_39[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 4, 4, 1024)   0           add_13[0][0]                     \n__________________________________________________________________________________________________\nres4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_40[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_41[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_42[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n                                                                 activation_40[0][0]              \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 4, 4, 1024)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nres5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_43[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_44[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n__________________________________________________________________________________________________\nres5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_43[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n                                                                 bn5a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\nres5b_branch2a (Conv2D)         (None, 2, 2, 256)    524544      activation_46[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res5b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 2, 2, 256)    0           bn5b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_47[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res5b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 2, 2, 256)    0           bn5b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5b_branch2c (Conv2D)         (None, 2, 2, 2048)   526336      activation_48[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n                                                                 activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 2, 2, 2048)   0           add_16[0][0]                     \n__________________________________________________________________________________________________\nres5c_branch2a (Conv2D)         (None, 2, 2, 256)    524544      activation_49[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res5c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 2, 2, 256)    0           bn5c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_50[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res5c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 2, 2, 256)    0           bn5c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5c_branch2c (Conv2D)         (None, 2, 2, 2048)   526336      activation_51[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_17 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n                                                                 activation_49[0][0]              \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 2, 2, 2048)   0           add_17[0][0]                     \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_52[0][0]              \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\nfc6 (Dense)                     (None, 6)            12294       flatten_1[0][0]                  \n==================================================================================================\nTotal params: 17,958,790\nTrainable params: 17,907,718\nNon-trainable params: 51,072\n__________________________________________________________________________________________________\n","name":"stdout"}],"source":"model.summary()"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"76844A2427B34863A146A190544CCF9B","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"最后，运行下面的代码以可视化你的ResNet50。你也可以通过转到\"File -> Open...-> model.png\".下载模型的.png图片。"},{"cell_type":"code","execution_count":19,"metadata":{"slideshow":{"slide_type":"slide"},"id":"A23E436407074B51BE9040325DD8553A","collapsed":false,"scrolled":true,"jupyter":{},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<IPython.core.display.SVG object>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/A23E436407074B51BE9040325DD8553A/q1q2nq6om6.svg\">"},"transient":{},"execution_count":19}],"source":"plot_model(model, to_file='model.png')\nSVG(model_to_dot(model).create(prog='dot', format='svg'))"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"BBA3DE2086AB46DF91DD93424FA0C54C","mdEditEnable":false,"jupyter":{},"tags":[],"trusted":true},"source":"**你应该记住的内容：**\n- 非常深的\"plain\"网络在实践中不起作用，因为梯度消失而难以训练。\n- skip-connections有助于解决梯度消失问题。它们还使ResNet块易于学习识别功能。\n- 块有两种主要类型：标识块和卷积块。\n- 通过将这些块堆叠在一起，可以构建非常深的残差网络。"},{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"},"id":"C55EF6D479414FAE88167E9BA2282596","jupyter":{},"tags":[],"mdEditEnable":false,"trusted":true},"source":"\n### 参考\n\n- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n- Francois Chollet's github repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}